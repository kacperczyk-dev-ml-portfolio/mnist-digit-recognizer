{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Digit Recognizer - MNIST\n",
    "##### https://www.kaggle.com/competitions/digit-recognizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In each row, first column contains a label (digit). The remainder 784 columns (28px x 28px image) contain pixel values of 0-255.\n",
    "mnist_df = pd.read_csv(\"data/train.csv\")\n",
    "mnist_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_df = mnist_df.sample(frac=1, axis=0)\n",
    "mnist_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transpose the data so that the first row will be equal to all the labels and the remainder of rows in each column will be the corresponding pixel value\n",
    "mnist_df_T = mnist_df.T\n",
    "mnist_df_T.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create NumPy array from Pandas dataframe\n",
    "mnist_arr = mnist_df_T.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_arr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shuffle columns\n",
    "# We could also do np.random.shufflle(mnist_arr.T) but below is supposed to be faster\n",
    "#mnist_arr = mnist_arr[:, np.random.permutation(mnist_arr.shape[1])]\n",
    "#mnist_arr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform a label so that 3 is represented by [0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0] instead of just 3\n",
    "def transform_label(label):\n",
    "    desired_output = np.zeros((10, 1))\n",
    "    desired_output[label] = 1.0\n",
    "    return desired_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = mnist_arr[0, :]\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform our labels so that 3 is represented by [0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0] instead of just 3\n",
    "# Each column is one example\n",
    "desired_outputs = np.array([transform_label(l) for l in labels]).T.reshape((10, 42000))\n",
    "desired_outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get all rows except the first one (because it contains labels), each column is one example\n",
    "# Since the pixelvalues are 0-255 we divide them by 255 to get values between 0 and 1 as activations of the input layer\n",
    "# Each row is one example\n",
    "pixel_rows = (mnist_arr[1:, :] / 255.0).T\n",
    "pixel_rows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup of weights and biases\n",
    "##### This will depend on the # of layers and the # of neurons in each of them.\n",
    "##### We will have 1 hidden layer with 30 neurons and 1 output layer with 10 neurons\n",
    "##### i.e. Network([784, 30, 10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers):\n",
    "        self.no_of_layers = len(layers)\n",
    "        self.layer_sizes = layers\n",
    "        self.weights = self.__init_weights()\n",
    "        self.biases = self.__init_biases()\n",
    "\n",
    "    def __init_weights(self):\n",
    "        # (784,30) and (30, 10) will be zipped, we will create two matrices with dimensions 30x784 and 10x30\n",
    "        return [np.random.randn(y, x) for x, y in zip(self.layer_sizes[:-1], self.layer_sizes[1:])]\n",
    "\n",
    "    def __init_biases(self):\n",
    "        # two arrays with 30, and 10 random numbers each\n",
    "        return [np.random.randn(x) for x in self.layer_sizes[1:]]\n",
    "\n",
    "    def __calculate_weighted_sums(self, activations, layer):\n",
    "        # weights is (30, 784) and activations is (784, X), the result will be (30, X)\n",
    "        # biases is (30, ), we need to transpose result so that it is (42000, 30), this way we can add biases\n",
    "        return (np.dot(self.weights[layer-1], activations).T + self.biases[layer-1]).T\n",
    "\n",
    "    # For activation we will use the sigmoid function\n",
    "    def calculate_activations(self, activations, layer):\n",
    "        z = self.__calculate_weighted_sums(activations, layer)\n",
    "        return self.sigmoid(z)\n",
    "\n",
    "    def feedforward(self, input_layer):\n",
    "        # Calculate activations for each layer.\n",
    "        # A contain activations in respective layers for each example\n",
    "        activations = [input_layer.T]\n",
    "        for l in range(self.no_of_layers-1):\n",
    "            activations.append(network.calculate_activations(activations[l], l+1))\n",
    "        return activations[1:]\n",
    "\n",
    "    def calculate_errors(self, activations, expected):\n",
    "        errors = [network.cost_derivative(activations[-1], expected) * network.sigmoid_derivative(activations[-1])]\n",
    "        for l in range(0, len(activations)-1)[::-1]:\n",
    "            errors.append(np.dot(self.weights[l+1].T, errors[-1]) * network.sigmoid_derivative(activations[l]))\n",
    "        return errors[::-1]\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_weight_deltas(activations, errors, mini_batch_size):\n",
    "        return [np.dot(e, a.T) / mini_batch_size for e, a in zip(errors, activations[0:len(activations)-1])]\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_bias_deltas(errors):\n",
    "            return [np.mean(e, 1) for e in errors]\n",
    "\n",
    "    def adjust_weights(self, weight_deltas, alpha):\n",
    "        self.weights = [self.weights[i] + (weight_deltas[i] * alpha) for i in range(len(weight_deltas))]\n",
    "\n",
    "    def adjust_biases(self, bias_deltas, alpha):\n",
    "        self.biases = [self.biases[i] + (bias_deltas[i] * alpha) for i in range(len(bias_deltas))]\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        # Sigmoid function, applied elementwise if z is a matrix\n",
    "        return 1 / (1 + np.exp(z))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(activations):\n",
    "        # sigmoid(z) * (1 - sigmoid(z))\n",
    "        # sigmoig(z) = activation so we can do it like below\n",
    "        return activations * (1 - activations)\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(output, expected):\n",
    "        return np.power((output-expected)/2, 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def cost_derivative(output, expected):\n",
    "        return output - expected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = Network([784, 30, 10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stochastic Gradient Descent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_accuracy(activations, actual):\n",
    "    max_indices = np.argmax(activations[-1], axis=0)\n",
    "    x = actual - max_indices\n",
    "    correct = x == 0\n",
    "    print(x[correct].size / actual.size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SGD(mini_batch_size, epochs, alpha):\n",
    "    for epoch in range(epochs):\n",
    "        random_number = np.random.randint(mini_batch_size, 42001)\n",
    "        inputs = pixel_rows[random_number - mini_batch_size : random_number, :]\n",
    "        activations = network.feedforward(inputs)\n",
    "        if epoch % 100 == 0:\n",
    "            calculate_accuracy(activations, labels[random_number - mini_batch_size : random_number])\n",
    "        errors_in_layers = network.calculate_errors(activations, desired_outputs[:, random_number - mini_batch_size : random_number])\n",
    "        inputs_and_activations = [inputs.T] + activations\n",
    "        weight_deltas = network.calculate_weight_deltas(inputs_and_activations, errors_in_layers, mini_batch_size)\n",
    "        bias_deltas = network.calculate_bias_deltas(errors_in_layers)\n",
    "        network.adjust_weights(weight_deltas, alpha)\n",
    "        network.adjust_biases(bias_deltas, alpha)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SGD(1000, 10000, 0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Calculate activations in the first and second layer.\n",
    "# # A1 & A2 contain activations in respective layers for each example\n",
    "# A1 = network.calculate_activations(pixel_rows.T, 1)\n",
    "# A2 = network.calculate_activations(A1, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# error_in_A2_layer = network.cost_derivative(A2, desired_outputs) * network.sigmoid_derivative(A2)\n",
    "# error_in_A1_layer = np.dot(network.weights[1].T, error_in_A2_layer) * network.sigmoid_derivative(A1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Gradient descent\n",
    "# deltaW2 = np.dot(error_in_A2_layer, A1.T) / 42000\n",
    "# deltaW2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deltaW1 = np.dot(error_in_A1_layer, pixel_rows) / 42000\n",
    "# deltaW1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deltaB2 = np.mean(error_in_A2_layer, 1)\n",
    "# deltaB2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deltaB1 = np.mean(error_in_A1_layer, 1)\n",
    "# deltaB1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
