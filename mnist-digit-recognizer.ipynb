{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Digit Recognizer - MNIST\n",
    "##### https://www.kaggle.com/competitions/digit-recognizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In each row, first column contains a label (digit). The remainder 784 columns (28px x 28px image) contain pixel values of 0-255.\n",
    "mnist_data = pd.read_csv(\"data/train.csv\")\n",
    "mnist_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shuffle data by rows\n",
    "mnist_data = mnist_data.sample(frac=1, axis=0)\n",
    "mnist_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transpose the data so that the first row will be equal to all the labels and the remainder of rows in each column will be the corresponding pixel value\n",
    "transposed_mnist_data = mnist_data.T\n",
    "transposed_mnist_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create NumPy array from Pandas dataframe\n",
    "mnist_data_arr = transposed_mnist_data.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_data_arr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Divide data into test and train sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Y will contain 41000 labels that will be used for training the network.\n",
    "# Label = a number from 0 to 9.\n",
    "Y = mnist_data_arr[0, 1000:]\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Y_test contains 1000 labels that will be used to evaluate the network after each training epoch\n",
    "Y_test = mnist_data_arr[0, :1000]\n",
    "Y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X will contain 41000 columns, each representing one training examples, each column/example contains 784 pixel values.\n",
    "# Because the pixelvalues are between 0 and 255, and we want them to be between 0 and 1, we will divide by 255.0\n",
    "# Each column corresponds to one label from Y\n",
    "X = (mnist_data_arr[1:, 1000:] / 255.0)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_test contains examples just like X but in X_test's case there is only 1000 examples that correspond to the labels from Y_test\n",
    "X_test = (mnist_data_arr[1:, :1000] / 255.0)\n",
    "X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform a label so that 3 is represented by a column vector of [0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0] instead of just 3\n",
    "# This is needed because the output layer of our network contains 10 neurons, each representing a number from 0 to 9\n",
    "def one_hot(y):\n",
    "    desired_output = np.zeros((10, 1))\n",
    "    desired_output[y] = 1.0\n",
    "    return desired_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform all our labels from Y using one_hot function defined above\n",
    "# Each column is one example\n",
    "one_hot_Y = np.array([one_hot(y) for y in Y]).T.reshape((10, 41000))\n",
    "one_hot_Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup of weights and biases\n",
    "##### This will depend on the # of layers and the # of neurons in each of them.\n",
    "##### We will have 1 hidden layer with 30 neurons and 1 output layer with 10 neurons\n",
    "##### Our input layer will be the MNIST date which is 784 rows (==neurons)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W1 = np.random.rand(30, 784) - 0.5 # Weights matrix between input layer and first layer\n",
    "W2 = np.random.rand(10, 30)  - 0.5 # Weights matrix between first layer and output layer\n",
    "b1 = np.random.rand(30, 1)   - 0.5 # Biases vector in first layer\n",
    "b2 = np.random.rand(10, 1)   - 0.5 # biases vector in output layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper functions\n",
    "##### Below functions are need to calculate the cost, activations, and errors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    # Sigmoid function, applied elementwise if z is a matrix\n",
    "    return 1.0 / (1.0 + np.exp(-Z))\n",
    "\n",
    "def sigmoid_derivative(Z):\n",
    "    # sigmoid(z) * (1 - sigmoid(z))\n",
    "    # sigmoig(z) = activation so we can do it like below\n",
    "    return sigmoid(Z) * (1.0 - sigmoid(Z))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cost(A, Y):\n",
    "    return np.power((A - Y) / 2, 2)\n",
    "\n",
    "def cost_derivative(A, Y):\n",
    "    return A - Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Below function will output % of predictions that match the expected output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, expected):\n",
    "    max_indices = np.argmax(predictions, axis=0) # Transform each prediction (10 neurons from output layer) into one number between 0 and 9\n",
    "    print(np.sum(max_indices == expected) / len(expected) * 100, \"%\") # Calculate % of predictions that are correct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stochastic Gradient Descent\n",
    "#### Instead of going through all examples each time we take a random sampling of sample_size\n",
    "#### We will train our model n number of times, where n = epochs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup hyperparameters\n",
    "epochs = 1000\n",
    "sample_size = 100\n",
    "learning_rate = 0.5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Create a random number between 1000 + sample_size and 41000, this is because the first 1000 examples from MNIST data are used for checking network's accuracy\n",
    "    random_int = np.random.randint(1000 + sample_size, 41001)\n",
    "\n",
    "    # Take a random sample of 100 examples from X\n",
    "    X_sample = X[:, random_int - sample_size : random_int]\n",
    "    # Take corresponding labels in one_hot form\n",
    "    one_hot_Y_sample = one_hot_Y[:, random_int - sample_size : random_int]\n",
    "\n",
    "    # Feedforward\n",
    "    #   Calculate activations in the first and second layer.\n",
    "    Z1 = np.dot(W1, X_sample) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2) # this will be our output\n",
    "\n",
    "    # Backpropagation\n",
    "    #   Calculate error in the output layer and backpropagate it to the first layer\n",
    "    error_A2 = cost_derivative(A2, one_hot_Y_sample) * sigmoid_derivative(Z2) # Fundamental equation of backpropagation #1\n",
    "    error_A1 = np.dot(W2.T, error_A2) # Fundamental equation of backpropagation #2\n",
    "\n",
    "    #   Gradient descent\n",
    "    #       Calculate how much does the cost function depend on each weight and bias\n",
    "    delta_W2 = np.dot(error_A2, A1.T)        / sample_size # Fundamental equation of backpropagation #4\n",
    "    delta_W1 = np.dot(error_A1, X_sample.T)  / sample_size # Fundamental equation of backpropagation #4\n",
    "    delta_b2 = np.sum(error_A2)              / sample_size # Fundamental equation of backpropagation #3\n",
    "    delta_b1 = np.sum(error_A1)              / sample_size # Fundamental equation of backpropagation #3\n",
    "    #       Use above calculations to adjust weights and biases accordingly\n",
    "    W1 = W1 - delta_W1 * learning_rate\n",
    "    W2 = W2 - delta_W2 * learning_rate\n",
    "    b1 = b1 - delta_b1 * learning_rate\n",
    "    b2 = b2 - delta_b2 * learning_rate\n",
    "\n",
    "    # Feedforward => checking accuracy using X_test data\n",
    "    # A2 will be the output for X_test\n",
    "    Z1 = np.dot(W1, X_test) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    # Every 100 iterations we will print the current accuracy of the network\n",
    "    if epoch % 100 == 0:\n",
    "        calculate_accuracy(A2, Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verifying\n",
    "### After all of the above cells are run our network will have weights and biases set\n",
    "### We can then use the below function to test those weights and biases to see how well the network performs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_weights_and_biases(idx):\n",
    "    current_image = X[:, idx, None]\n",
    "\n",
    "    Z1 = np.dot(W1, current_image) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    label = Y[idx]\n",
    "\n",
    "    print(\"Prediction: \", np.argmax(A2))\n",
    "    print(\"Label:      \", label)\n",
    "\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We feed an index between 0 and 41000\n",
    "# The function outputs the following:\n",
    "# Prediction = what the network thinks the number is\n",
    "# Label      = the actual number\n",
    "# A 28x28 pixel photo of the number\n",
    "test_weights_and_biases(40121)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
